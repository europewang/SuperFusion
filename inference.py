#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SuperFusion æ¨ç†è„šæœ¬
ç›´æ¥è°ƒç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼Œè¾“å…¥ç‚¹äº‘+å›¾ç‰‡ï¼Œè¾“å‡ºè½¦é“çº¿

ä½¿ç”¨æ–¹æ³•:
python inference.py --model_path runs/model.pt --input_data sample_data/ --output_dir results/
"""

import os
import sys
import argparse
import torch
import numpy as np
import cv2
from pathlib import Path
import json
from PIL import Image
import matplotlib.pyplot as plt

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('.')

class SuperFusionInference:
    """SuperFusionæ¨ç†ç±»"""
    
    def __init__(self, model_path, device='cuda'):
        """
        åˆå§‹åŒ–æ¨ç†å™¨
        
        Args:
            model_path: é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
            device: è®¡ç®—è®¾å¤‡ ('cuda' æˆ– 'cpu')
        """
        self.device = device if torch.cuda.is_available() else 'cpu'
        self.model = self._load_model(model_path)
        self.model.eval()
        
        # BEVå‚æ•° (ä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´)
        self.bev_params = {
            'xbound': [-50.0, 50.0, 0.5],
            'ybound': [-50.0, 50.0, 0.5],
            'zbound': [-10.0, 10.0, 20.0],
            'dbound': [4.0, 45.0, 1.0]
        }
        
        # å›¾åƒå‚æ•°
        self.img_size = (256, 704)  # (H, W)
        
        print(f"âœ“ SuperFusionæ¨ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"âœ“ è®¾å¤‡: {self.device}")
        print(f"âœ“ æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in self.model.parameters())/1e6:.2f}M")
    
    def _load_model(self, model_path):
        """åŠ è½½é¢„è®­ç»ƒæ¨¡å‹"""
        from model_front import get_model
        
        # åˆ›å»ºæ¨¡å‹é…ç½® (ä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´)
        args = type('Args', (), {
            'instance_seg': True,
            'direction_pred': True,
            'depth_sup': True,
            'add_depth_channel': True,
            'pretrained': True,
            'camC': 64,
            'lidarC': 64,
            'downsample': 16,
            'use_lidar': True,
            'use_cam': True,
            'use_fusion': True,
            'add_fuser': True
        })()
        
        # åˆ›å»ºæ¨¡å‹
        model = get_model('SuperFusion', args)
        
        # åŠ è½½æƒé‡
        if os.path.exists(model_path):
            checkpoint = torch.load(model_path, map_location=self.device)
            if isinstance(checkpoint, dict) and 'model' in checkpoint:
                model.load_state_dict(checkpoint['model'])
            else:
                model.load_state_dict(checkpoint)
            print(f"âœ“ åŠ è½½æ¨¡å‹æƒé‡: {model_path}")
        else:
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        
        return model.to(self.device)
    
    def preprocess_images(self, image_paths):
        """
        é¢„å¤„ç†å›¾åƒæ•°æ®
        
        Args:
            image_paths: 6ä¸ªç›¸æœºå›¾åƒè·¯å¾„åˆ—è¡¨
            
        Returns:
            torch.Tensor: é¢„å¤„ç†åçš„å›¾åƒå¼ é‡ [1, 6, 3, H, W]
        """
        if len(image_paths) != 6:
            raise ValueError(f"éœ€è¦6ä¸ªç›¸æœºå›¾åƒï¼Œä½†æä¾›äº†{len(image_paths)}ä¸ª")
        
        images = []
        for img_path in image_paths:
            if not os.path.exists(img_path):
                raise FileNotFoundError(f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {img_path}")
            
            # è¯»å–å›¾åƒ
            img = Image.open(img_path).convert('RGB')
            img = img.resize((self.img_size[1], self.img_size[0]))  # (W, H)
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„å¹¶å½’ä¸€åŒ–
            img = np.array(img).astype(np.float32) / 255.0
            
            # æ ‡å‡†åŒ– (ImageNetç»Ÿè®¡)
            mean = np.array([0.485, 0.456, 0.406])
            std = np.array([0.229, 0.224, 0.225])
            img = (img - mean) / std
            
            # è½¬æ¢ä¸ºCHWæ ¼å¼
            img = img.transpose(2, 0, 1)
            images.append(img)
        
        # å †å ä¸ºå¼ é‡
        images = np.stack(images, axis=0)  # [6, 3, H, W]
        images = torch.from_numpy(images).unsqueeze(0)  # [1, 6, 3, H, W]
        
        return images.to(self.device)
    
    def preprocess_lidar(self, lidar_path):
        """
        é¢„å¤„ç†æ¿€å…‰é›·è¾¾æ•°æ®
        
        Args:
            lidar_path: æ¿€å…‰é›·è¾¾BEVç‰¹å¾æ–‡ä»¶è·¯å¾„ (.npyæ ¼å¼)
            
        Returns:
            torch.Tensor: é¢„å¤„ç†åçš„æ¿€å…‰é›·è¾¾å¼ é‡ [1, C, H, W]
        """
        if not os.path.exists(lidar_path):
            raise FileNotFoundError(f"æ¿€å…‰é›·è¾¾æ–‡ä»¶ä¸å­˜åœ¨: {lidar_path}")
        
        # åŠ è½½æ¿€å…‰é›·è¾¾BEVç‰¹å¾
        if lidar_path.endswith('.npy'):
            lidar_data = np.load(lidar_path)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¿€å…‰é›·è¾¾æ–‡ä»¶æ ¼å¼: {lidar_path}")
        
        # ç¡®ä¿æ•°æ®æ ¼å¼æ­£ç¡®
        if lidar_data.ndim == 3:  # [C, H, W]
            lidar_data = lidar_data[np.newaxis, ...]  # [1, C, H, W]
        elif lidar_data.ndim == 2:  # [H, W]
            lidar_data = lidar_data[np.newaxis, np.newaxis, ...]  # [1, 1, H, W]
        
        # è½¬æ¢ä¸ºå¼ é‡
        lidar_tensor = torch.from_numpy(lidar_data.astype(np.float32))
        
        return lidar_tensor.to(self.device)
    
    def predict(self, image_paths, lidar_path):
        """
        æ‰§è¡Œæ¨ç†é¢„æµ‹
        
        Args:
            image_paths: 6ä¸ªç›¸æœºå›¾åƒè·¯å¾„åˆ—è¡¨
            lidar_path: æ¿€å…‰é›·è¾¾BEVç‰¹å¾æ–‡ä»¶è·¯å¾„
            
        Returns:
            dict: é¢„æµ‹ç»“æœå­—å…¸
        """
        # é¢„å¤„ç†è¾“å…¥æ•°æ®
        images = self.preprocess_images(image_paths)
        lidar_data = self.preprocess_lidar(lidar_path)
        
        print(f"âœ“ å›¾åƒæ•°æ®å½¢çŠ¶: {images.shape}")
        print(f"âœ“ æ¿€å…‰é›·è¾¾æ•°æ®å½¢çŠ¶: {lidar_data.shape}")
        
        # æ¨¡å‹æ¨ç†
        with torch.no_grad():
            output = self.model(images, lidar_data)
        
        # åå¤„ç†é¢„æµ‹ç»“æœ
        results = self._postprocess_output(output)
        
        return results
    
    def _postprocess_output(self, output):
        """
        åå¤„ç†æ¨¡å‹è¾“å‡º
        
        Args:
            output: æ¨¡å‹åŸå§‹è¾“å‡º
            
        Returns:
            dict: å¤„ç†åçš„ç»“æœ
        """
        results = {}
        
        # è¯­ä¹‰åˆ†å‰²ç»“æœ
        if isinstance(output, (list, tuple)):
            seg_output = output[0]
        else:
            seg_output = output
        
        # åº”ç”¨sigmoidæ¿€æ´»
        seg_prob = torch.sigmoid(seg_output)
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        seg_prob_np = seg_prob.cpu().numpy()[0]  # [C, H, W]
        
        # äºŒå€¼åŒ– (é˜ˆå€¼0.5)
        seg_binary = (seg_prob_np > 0.5).astype(np.uint8)
        
        results['segmentation'] = {
            'probability': seg_prob_np,
            'binary': seg_binary,
            'shape': seg_prob_np.shape
        }
        
        # å¦‚æœæœ‰å¤šä¸ªè¾“å‡ºï¼Œå¤„ç†å…¶ä»–ä»»åŠ¡
        if isinstance(output, (list, tuple)) and len(output) > 1:
            # å®ä¾‹åˆ†å‰²
            if len(output) > 1:
                embedding = output[1].cpu().numpy()[0]
                results['embedding'] = embedding
            
            # æ–¹å‘é¢„æµ‹
            if len(output) > 2:
                direction = output[2].cpu().numpy()[0]
                results['direction'] = direction
        
        return results
    
    def visualize_results(self, results, save_path=None):
        """
        å¯è§†åŒ–é¢„æµ‹ç»“æœ
        
        Args:
            results: é¢„æµ‹ç»“æœå­—å…¸
            save_path: ä¿å­˜è·¯å¾„
        """
        seg_data = results['segmentation']
        
        # åˆ›å»ºå¯è§†åŒ–å›¾åƒ
        fig, axes = plt.subplots(1, 2, figsize=(12, 5))
        
        # æ¦‚ç‡å›¾
        if seg_data['probability'].shape[0] > 1:
            # å¤šç±»åˆ«ï¼Œæ˜¾ç¤ºç¬¬ä¸€ä¸ªç±»åˆ«
            prob_map = seg_data['probability'][0]
        else:
            prob_map = seg_data['probability'][0]
        
        axes[0].imshow(prob_map, cmap='viridis')
        axes[0].set_title('è½¦é“çº¿æ¦‚ç‡å›¾')
        axes[0].axis('off')
        
        # äºŒå€¼åŒ–ç»“æœ
        if seg_data['binary'].shape[0] > 1:
            binary_map = seg_data['binary'][0]
        else:
            binary_map = seg_data['binary'][0]
        
        axes[1].imshow(binary_map, cmap='gray')
        axes[1].set_title('è½¦é“çº¿æ£€æµ‹ç»“æœ')
        axes[1].axis('off')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            print(f"âœ“ å¯è§†åŒ–ç»“æœä¿å­˜åˆ°: {save_path}")
        else:
            plt.show()
        
        plt.close()
    
    def vectorize_lanes(self, results):
        """
        å°†åˆ†å‰²ç»“æœçŸ¢é‡åŒ–ä¸ºè½¦é“çº¿
        
        Args:
            results: é¢„æµ‹ç»“æœå­—å…¸
            
        Returns:
            list: è½¦é“çº¿çŸ¢é‡åˆ—è¡¨
        """
        try:
            from postprocess.vectorize import vectorize
            
            seg_binary = results['segmentation']['binary']
            
            # å¦‚æœæœ‰åµŒå…¥ç‰¹å¾ï¼Œä½¿ç”¨å®Œæ•´çš„çŸ¢é‡åŒ–
            if 'embedding' in results:
                embedding = results['embedding']
                direction = results.get('direction', None)
                
                # è°ƒç”¨çŸ¢é‡åŒ–å‡½æ•°
                vectors = vectorize(
                    seg_binary[0] if seg_binary.shape[0] > 1 else seg_binary,
                    embedding,
                    direction
                )
            else:
                # ç®€å•çš„è½®å»“æå–
                vectors = self._simple_vectorize(seg_binary[0] if seg_binary.shape[0] > 1 else seg_binary)
            
            return vectors
            
        except ImportError:
            print("âš ï¸ çŸ¢é‡åŒ–æ¨¡å—ä¸å¯ç”¨ï¼Œä½¿ç”¨ç®€å•è½®å»“æå–")
            return self._simple_vectorize(seg_binary[0] if seg_binary.shape[0] > 1 else seg_binary)
    
    def _simple_vectorize(self, binary_mask):
        """
        ç®€å•çš„è½®å»“æå–çŸ¢é‡åŒ–
        
        Args:
            binary_mask: äºŒå€¼åŒ–æ©ç 
            
        Returns:
            list: è½®å»“ç‚¹åˆ—è¡¨
        """
        import cv2
        
        # æŸ¥æ‰¾è½®å»“
        contours, _ = cv2.findContours(
            binary_mask.astype(np.uint8), 
            cv2.RETR_EXTERNAL, 
            cv2.CHAIN_APPROX_SIMPLE
        )
        
        # è½¬æ¢ä¸ºè½¦é“çº¿æ ¼å¼
        lanes = []
        for contour in contours:
            if len(contour) > 10:  # è¿‡æ»¤å¤ªçŸ­çš„è½®å»“
                # ç®€åŒ–è½®å»“
                epsilon = 0.02 * cv2.arcLength(contour, True)
                approx = cv2.approxPolyDP(contour, epsilon, True)
                
                # è½¬æ¢ä¸ºBEVåæ ‡
                lane_points = []
                for point in approx:
                    x, y = point[0]
                    # è½¬æ¢ä¸ºå®é™…åæ ‡ (æ ¹æ®BEVå‚æ•°)
                    real_x = (x / binary_mask.shape[1]) * (self.bev_params['xbound'][1] - self.bev_params['xbound'][0]) + self.bev_params['xbound'][0]
                    real_y = (y / binary_mask.shape[0]) * (self.bev_params['ybound'][1] - self.bev_params['ybound'][0]) + self.bev_params['ybound'][0]
                    lane_points.append([real_x, real_y])
                
                lanes.append(lane_points)
        
        return lanes

def main():
    parser = argparse.ArgumentParser(description='SuperFusionæ¨ç†è„šæœ¬')
    parser.add_argument('--model_path', type=str, required=True, help='é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„')
    parser.add_argument('--images', type=str, nargs=6, required=True, 
                       help='6ä¸ªç›¸æœºå›¾åƒè·¯å¾„ (æŒ‰é¡ºåº: front, front_right, front_left, back, back_left, back_right)')
    parser.add_argument('--lidar', type=str, required=True, help='æ¿€å…‰é›·è¾¾BEVç‰¹å¾æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output_dir', type=str, default='inference_results', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--visualize', action='store_true', help='å¯è§†åŒ–ç»“æœ')
    parser.add_argument('--vectorize', action='store_true', help='çŸ¢é‡åŒ–è½¦é“çº¿')
    parser.add_argument('--device', type=str, default='cuda', choices=['cuda', 'cpu'], help='è®¡ç®—è®¾å¤‡')
    
    args = parser.parse_args()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)
    
    print("ğŸš€ SuperFusionæ¨ç†å¼€å§‹")
    print("=" * 50)
    
    try:
        # åˆå§‹åŒ–æ¨ç†å™¨
        inferencer = SuperFusionInference(args.model_path, args.device)
        
        # æ‰§è¡Œæ¨ç†
        print("\nğŸ” æ‰§è¡Œæ¨ç†...")
        results = inferencer.predict(args.images, args.lidar)
        
        print(f"âœ“ æ¨ç†å®Œæˆ")
        print(f"âœ“ åˆ†å‰²ç»“æœå½¢çŠ¶: {results['segmentation']['shape']}")
        
        # ä¿å­˜ç»“æœ
        result_file = os.path.join(args.output_dir, 'prediction_results.npz')
        np.savez(result_file, **results['segmentation'])
        print(f"âœ“ ç»“æœä¿å­˜åˆ°: {result_file}")
        
        # å¯è§†åŒ–
        if args.visualize:
            print("\nğŸ¨ ç”Ÿæˆå¯è§†åŒ–...")
            vis_path = os.path.join(args.output_dir, 'visualization.png')
            inferencer.visualize_results(results, vis_path)
        
        # çŸ¢é‡åŒ–
        if args.vectorize:
            print("\nğŸ“ çŸ¢é‡åŒ–è½¦é“çº¿...")
            lanes = inferencer.vectorize_lanes(results)
            
            # ä¿å­˜çŸ¢é‡ç»“æœ
            vector_file = os.path.join(args.output_dir, 'lane_vectors.json')
            with open(vector_file, 'w') as f:
                json.dump({
                    'lanes': lanes,
                    'bev_params': inferencer.bev_params,
                    'num_lanes': len(lanes)
                }, f, indent=2)
            
            print(f"âœ“ æ£€æµ‹åˆ° {len(lanes)} æ¡è½¦é“çº¿")
            print(f"âœ“ çŸ¢é‡ç»“æœä¿å­˜åˆ°: {vector_file}")
        
        print("\n" + "=" * 50)
        print("ğŸ‰ æ¨ç†å®Œæˆ!")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {args.output_dir}/")
        
    except Exception as e:
        print(f"âŒ æ¨ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0

if __name__ == '__main__':
    exit(main())