#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SuperFusion è°ƒè¯•å·¥å…·é›†
æä¾›æ¨¡å‹åˆ†æã€æ•°æ®æ£€æŸ¥ã€é”™è¯¯è¯Šæ–­ç­‰åŠŸèƒ½

ä½¿ç”¨æ–¹æ³•:
python debug_tools.py --analyze-model          # åˆ†ææ¨¡å‹ç»“æ„
python debug_tools.py --check-gradients        # æ£€æŸ¥æ¢¯åº¦æµ
python debug_tools.py --profile-memory         # å†…å­˜åˆ†æ
python debug_tools.py --test-dataloader        # æµ‹è¯•æ•°æ®åŠ è½½å™¨
python debug_tools.py --visualize-features     # å¯è§†åŒ–ç‰¹å¾
"""

import os
import sys
import argparse
import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import time
import psutil
import gc

def analyze_model(model_name='SuperFusion'):
    """åˆ†ææ¨¡å‹ç»“æ„å’Œå‚æ•°"""
    print(f"\nğŸ” åˆ†ææ¨¡å‹: {model_name}")
    
    try:
        sys.path.append('.')
        from model_front import get_model
        
        # åˆ›å»ºæ¨¡å‹é…ç½®
        args = type('Args', (), {
            'instance_seg': True,
            'direction_pred': True,
            'depth_sup': True,
            'add_depth_channel': True,
            'pretrained': True,
            'camC': 64,
            'lidarC': 64,
            'downsample': 16,
            'use_lidar': True,
            'use_cam': True,
            'use_fusion': True,
            'add_fuser': True
        })()
        
        model = get_model(model_name, args)
        
        print("\nğŸ“Š æ¨¡å‹ç»Ÿè®¡ä¿¡æ¯:")
        
        # å‚æ•°ç»Ÿè®¡
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        frozen_params = total_params - trainable_params
        
        print(f"æ€»å‚æ•°é‡: {total_params:,} ({total_params/1e6:.2f}M)")
        print(f"å¯è®­ç»ƒå‚æ•°: {trainable_params:,} ({trainable_params/1e6:.2f}M)")
        print(f"å†»ç»“å‚æ•°: {frozen_params:,} ({frozen_params/1e6:.2f}M)")
        
        # æ¨¡å‹å¤§å°ä¼°ç®—
        param_size = total_params * 4 / (1024 ** 2)  # å‡è®¾float32
        print(f"æ¨¡å‹å¤§å° (å‚æ•°): {param_size:.2f} MB")
        
        # å±‚çº§åˆ†æ
        print("\nğŸ—ï¸ æ¨¡å‹ç»“æ„åˆ†æ:")
        layer_count = {}
        for name, module in model.named_modules():
            module_type = type(module).__name__
            layer_count[module_type] = layer_count.get(module_type, 0) + 1
        
        for layer_type, count in sorted(layer_count.items()):
            if count > 1:
                print(f"{layer_type}: {count}")
        
        # å„æ¨¡å—å‚æ•°åˆ†å¸ƒ
        print("\nğŸ“ˆ å„æ¨¡å—å‚æ•°åˆ†å¸ƒ:")
        module_params = {}
        for name, param in model.named_parameters():
            module_name = name.split('.')[0]
            if module_name not in module_params:
                module_params[module_name] = 0
            module_params[module_name] += param.numel()
        
        for module_name, param_count in sorted(module_params.items(), key=lambda x: x[1], reverse=True):
            print(f"{module_name}: {param_count:,} ({param_count/1e6:.2f}M)")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def check_gradients(model_path=None, dataroot='/path/to/nuScenes/'):
    """æ£€æŸ¥æ¢¯åº¦æµ"""
    print("\nğŸ” æ£€æŸ¥æ¢¯åº¦æµ...")
    
    try:
        sys.path.append('.')
        from model_front import get_model
        from data.dataset_front import semantic_dataset
        from loss import SimpleLoss
        
        # åˆ›å»ºæ¨¡å‹
        args = type('Args', (), {
            'instance_seg': False,
            'direction_pred': False,
            'depth_sup': False,
            'add_depth_channel': False,
            'pretrained': True,
            'camC': 64,
            'lidarC': 64,
            'downsample': 16,
            'use_lidar': True,
            'use_cam': True,
            'use_fusion': True,
            'add_fuser': True
        })()
        
        model = get_model('SuperFusion', args)
        
        if model_path and os.path.exists(model_path):
            model.load_state_dict(torch.load(model_path, map_location='cpu'))
            print(f"âœ“ åŠ è½½æ¨¡å‹: {model_path}")
        
        # åˆ›å»ºæ•°æ®
        dataset = semantic_dataset(dataroot, 'v1.0-trainval')
        dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, num_workers=0)
        sample = next(iter(dataloader))
        
        # åˆ›å»ºæŸå¤±å‡½æ•°
        loss_fn = SimpleLoss(pos_weight=2.13)
        
        if torch.cuda.is_available():
            model = model.cuda()
            loss_fn = loss_fn.cuda()
            sample = [s.cuda() if torch.is_tensor(s) else s for s in sample]
        
        # å‰å‘ä¼ æ’­
        model.train()
        imgs, lidar_data, binimgs = sample[0], sample[1], sample[2]
        output = model(imgs, lidar_data)
        loss = loss_fn(output, binimgs)
        
        # åå‘ä¼ æ’­
        loss.backward()
        
        print(f"\nğŸ“Š æ¢¯åº¦ç»Ÿè®¡ (æŸå¤±å€¼: {loss.item():.4f}):")
        
        # æ£€æŸ¥æ¢¯åº¦
        grad_stats = []
        for name, param in model.named_parameters():
            if param.grad is not None:
                grad_norm = param.grad.norm().item()
                grad_mean = param.grad.mean().item()
                grad_std = param.grad.std().item()
                grad_stats.append((name, grad_norm, grad_mean, grad_std))
        
        # æŒ‰æ¢¯åº¦èŒƒæ•°æ’åº
        grad_stats.sort(key=lambda x: x[1], reverse=True)
        
        print("\nğŸ” æ¢¯åº¦èŒƒæ•°æœ€å¤§çš„10ä¸ªå‚æ•°:")
        for i, (name, norm, mean, std) in enumerate(grad_stats[:10]):
            print(f"{i+1:2d}. {name:30s} | èŒƒæ•°: {norm:8.4f} | å‡å€¼: {mean:8.4f} | æ ‡å‡†å·®: {std:8.4f}")
        
        print("\nğŸ”» æ¢¯åº¦èŒƒæ•°æœ€å°çš„10ä¸ªå‚æ•°:")
        for i, (name, norm, mean, std) in enumerate(grad_stats[-10:]):
            print(f"{i+1:2d}. {name:30s} | èŒƒæ•°: {norm:8.4f} | å‡å€¼: {mean:8.4f} | æ ‡å‡†å·®: {std:8.4f}")
        
        # æ£€æŸ¥æ¢¯åº¦æ¶ˆå¤±/çˆ†ç‚¸
        zero_grads = sum(1 for _, norm, _, _ in grad_stats if norm < 1e-7)
        large_grads = sum(1 for _, norm, _, _ in grad_stats if norm > 1.0)
        
        print(f"\nâš ï¸  æ¢¯åº¦è¯Šæ–­:")
        print(f"é›¶æ¢¯åº¦å‚æ•°: {zero_grads}/{len(grad_stats)} ({zero_grads/len(grad_stats)*100:.1f}%)")
        print(f"å¤§æ¢¯åº¦å‚æ•°: {large_grads}/{len(grad_stats)} ({large_grads/len(grad_stats)*100:.1f}%)")
        
        if zero_grads > len(grad_stats) * 0.5:
            print("âŒ å¯èƒ½å­˜åœ¨æ¢¯åº¦æ¶ˆå¤±é—®é¢˜")
        elif large_grads > len(grad_stats) * 0.1:
            print("âŒ å¯èƒ½å­˜åœ¨æ¢¯åº¦çˆ†ç‚¸é—®é¢˜")
        else:
            print("âœ… æ¢¯åº¦æµæ­£å¸¸")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¢¯åº¦æ£€æŸ¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def profile_memory(model_name='SuperFusion', batch_size=1):
    """å†…å­˜ä½¿ç”¨åˆ†æ"""
    print(f"\nğŸ” å†…å­˜ä½¿ç”¨åˆ†æ (æ‰¹æ¬¡å¤§å°: {batch_size})...")
    
    try:
        sys.path.append('.')
        from model_front import get_model
        
        # è®°å½•åˆå§‹å†…å­˜
        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            initial_gpu_memory = torch.cuda.memory_allocated() / 1024 / 1024  # MB
        
        print(f"åˆå§‹CPUå†…å­˜: {initial_memory:.1f} MB")
        if torch.cuda.is_available():
            print(f"åˆå§‹GPUå†…å­˜: {initial_gpu_memory:.1f} MB")
        
        # åˆ›å»ºæ¨¡å‹
        args = type('Args', (), {
            'instance_seg': True,
            'direction_pred': True,
            'depth_sup': True,
            'add_depth_channel': True,
            'pretrained': True,
            'camC': 64,
            'lidarC': 64,
            'downsample': 16,
            'use_lidar': True,
            'use_cam': True,
            'use_fusion': True,
            'add_fuser': True
        })()
        
        model = get_model(model_name, args)
        
        # æ¨¡å‹åŠ è½½åå†…å­˜
        model_memory = process.memory_info().rss / 1024 / 1024
        print(f"æ¨¡å‹åŠ è½½åCPUå†…å­˜: {model_memory:.1f} MB (+{model_memory-initial_memory:.1f} MB)")
        
        if torch.cuda.is_available():
            model = model.cuda()
            model_gpu_memory = torch.cuda.memory_allocated() / 1024 / 1024
            print(f"æ¨¡å‹åŠ è½½åˆ°GPUåå†…å­˜: {model_gpu_memory:.1f} MB (+{model_gpu_memory-initial_gpu_memory:.1f} MB)")
        
        # åˆ›å»ºè¾“å…¥æ•°æ®
        imgs = torch.randn(batch_size, 6, 3, 256, 704)
        lidar_data = torch.randn(batch_size, 5, 256, 704)
        
        if torch.cuda.is_available():
            imgs = imgs.cuda()
            lidar_data = lidar_data.cuda()
        
        # è¾“å…¥æ•°æ®å†…å­˜
        input_memory = process.memory_info().rss / 1024 / 1024
        if torch.cuda.is_available():
            input_gpu_memory = torch.cuda.memory_allocated() / 1024 / 1024
            print(f"è¾“å…¥æ•°æ®åŠ è½½åGPUå†…å­˜: {input_gpu_memory:.1f} MB (+{input_gpu_memory-model_gpu_memory:.1f} MB)")
        
        # å‰å‘ä¼ æ’­
        model.eval()
        with torch.no_grad():
            output = model(imgs, lidar_data)
        
        # å‰å‘ä¼ æ’­åå†…å­˜
        forward_memory = process.memory_info().rss / 1024 / 1024
        if torch.cuda.is_available():
            forward_gpu_memory = torch.cuda.memory_allocated() / 1024 / 1024
            print(f"å‰å‘ä¼ æ’­åGPUå†…å­˜: {forward_gpu_memory:.1f} MB (+{forward_gpu_memory-input_gpu_memory:.1f} MB)")
        
        # åå‘ä¼ æ’­æµ‹è¯•
        model.train()
        output = model(imgs, lidar_data)
        loss = output.mean()  # ç®€å•æŸå¤±
        loss.backward()
        
        # åå‘ä¼ æ’­åå†…å­˜
        backward_memory = process.memory_info().rss / 1024 / 1024
        if torch.cuda.is_available():
            backward_gpu_memory = torch.cuda.memory_allocated() / 1024 / 1024
            print(f"åå‘ä¼ æ’­åGPUå†…å­˜: {backward_gpu_memory:.1f} MB (+{backward_gpu_memory-forward_gpu_memory:.1f} MB)")
        
        print(f"\nğŸ“Š å†…å­˜ä½¿ç”¨æ€»ç»“:")
        print(f"æ¨¡å‹å‚æ•°å†…å­˜: {model_memory-initial_memory:.1f} MB")
        if torch.cuda.is_available():
            print(f"GPUæ€»å†…å­˜ä½¿ç”¨: {backward_gpu_memory:.1f} MB")
            print(f"GPUå¯ç”¨å†…å­˜: {torch.cuda.get_device_properties(0).total_memory/1024/1024 - backward_gpu_memory:.1f} MB")
        
        # å†…å­˜å»ºè®®
        if torch.cuda.is_available():
            total_gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024 / 1024
            memory_usage_ratio = backward_gpu_memory / total_gpu_memory
            
            print(f"\nğŸ’¡ å†…å­˜ä½¿ç”¨å»ºè®®:")
            if memory_usage_ratio > 0.9:
                print("âŒ GPUå†…å­˜ä½¿ç”¨è¿‡é«˜ï¼Œå»ºè®®å‡å°æ‰¹æ¬¡å¤§å°")
                suggested_batch_size = max(1, int(batch_size * 0.8 / memory_usage_ratio))
                print(f"å»ºè®®æ‰¹æ¬¡å¤§å°: {suggested_batch_size}")
            elif memory_usage_ratio < 0.5:
                print("âœ… GPUå†…å­˜ä½¿ç”¨è¾ƒä½ï¼Œå¯ä»¥å¢å¤§æ‰¹æ¬¡å¤§å°")
                suggested_batch_size = int(batch_size * 0.8 / memory_usage_ratio)
                print(f"å»ºè®®æ‰¹æ¬¡å¤§å°: {suggested_batch_size}")
            else:
                print("âœ… GPUå†…å­˜ä½¿ç”¨åˆç†")
        
        return True
        
    except Exception as e:
        print(f"âŒ å†…å­˜åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_dataloader(dataroot, batch_size=4, num_workers=4):
    """æµ‹è¯•æ•°æ®åŠ è½½å™¨æ€§èƒ½"""
    print(f"\nğŸ” æµ‹è¯•æ•°æ®åŠ è½½å™¨ (æ‰¹æ¬¡å¤§å°: {batch_size}, å·¥ä½œè¿›ç¨‹: {num_workers})...")
    
    try:
        sys.path.append('.')
        from data.dataset_front import semantic_dataset
        
        # åˆ›å»ºæ•°æ®é›†
        dataset = semantic_dataset(dataroot, 'v1.0-trainval')
        print(f"âœ“ æ•°æ®é›†å¤§å°: {len(dataset)}")
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        dataloader = torch.utils.data.DataLoader(
            dataset, 
            batch_size=batch_size, 
            shuffle=True, 
            num_workers=num_workers,
            pin_memory=True if torch.cuda.is_available() else False
        )
        
        print(f"âœ“ æ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸ")
        print(f"âœ“ æ‰¹æ¬¡æ•°é‡: {len(dataloader)}")
        
        # æµ‹è¯•æ•°æ®åŠ è½½é€Ÿåº¦
        print("\nâ±ï¸ æµ‹è¯•æ•°æ®åŠ è½½é€Ÿåº¦...")
        
        start_time = time.time()
        batch_times = []
        
        for i, batch in enumerate(dataloader):
            batch_start = time.time()
            
            # æ£€æŸ¥æ•°æ®å½¢çŠ¶
            if i == 0:
                imgs, lidar_data, binimgs = batch[0], batch[1], batch[2]
                print(f"âœ“ å›¾åƒå½¢çŠ¶: {imgs.shape}")
                print(f"âœ“ æ¿€å…‰é›·è¾¾å½¢çŠ¶: {lidar_data.shape}")
                print(f"âœ“ æ ‡ç­¾å½¢çŠ¶: {binimgs.shape}")
                
                # æ£€æŸ¥æ•°æ®èŒƒå›´
                print(f"âœ“ å›¾åƒèŒƒå›´: [{imgs.min():.3f}, {imgs.max():.3f}]")
                print(f"âœ“ æ¿€å…‰é›·è¾¾èŒƒå›´: [{lidar_data.min():.3f}, {lidar_data.max():.3f}]")
                print(f"âœ“ æ ‡ç­¾èŒƒå›´: [{binimgs.min():.3f}, {binimgs.max():.3f}]")
            
            batch_end = time.time()
            batch_times.append(batch_end - batch_start)
            
            if i >= 10:  # åªæµ‹è¯•å‰10ä¸ªæ‰¹æ¬¡
                break
        
        total_time = time.time() - start_time
        avg_batch_time = np.mean(batch_times)
        
        print(f"\nğŸ“Š æ•°æ®åŠ è½½æ€§èƒ½:")
        print(f"æ€»æ—¶é—´: {total_time:.2f}s")
        print(f"å¹³å‡æ¯æ‰¹æ¬¡æ—¶é—´: {avg_batch_time:.3f}s")
        print(f"æ•°æ®åŠ è½½é€Ÿåº¦: {batch_size/avg_batch_time:.1f} æ ·æœ¬/ç§’")
        
        # æ€§èƒ½å»ºè®®
        if avg_batch_time > 1.0:
            print("\nğŸ’¡ æ€§èƒ½å»ºè®®:")
            print("âŒ æ•°æ®åŠ è½½è¾ƒæ…¢ï¼Œå»ºè®®:")
            print("  1. å¢åŠ num_workersæ•°é‡")
            print("  2. ä½¿ç”¨SSDå­˜å‚¨æ•°æ®")
            print("  3. å¯ç”¨pin_memory")
        else:
            print("\nâœ… æ•°æ®åŠ è½½é€Ÿåº¦æ­£å¸¸")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å™¨æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def visualize_features(model_path=None, dataroot='/path/to/nuScenes/', save_dir='debug_vis'):
    """å¯è§†åŒ–æ¨¡å‹ç‰¹å¾"""
    print(f"\nğŸ” å¯è§†åŒ–æ¨¡å‹ç‰¹å¾...")
    
    try:
        sys.path.append('.')
        from model_front import get_model
        from data.dataset_front import semantic_dataset
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        os.makedirs(save_dir, exist_ok=True)
        
        # åˆ›å»ºæ¨¡å‹
        args = type('Args', (), {
            'instance_seg': True,
            'direction_pred': True,
            'depth_sup': True,
            'add_depth_channel': True,
            'pretrained': True,
            'camC': 64,
            'lidarC': 64,
            'downsample': 16,
            'use_lidar': True,
            'use_cam': True,
            'use_fusion': True,
            'add_fuser': True
        })()
        
        model = get_model('SuperFusion', args)
        
        if model_path and os.path.exists(model_path):
            model.load_state_dict(torch.load(model_path, map_location='cpu'))
            print(f"âœ“ åŠ è½½æ¨¡å‹: {model_path}")
        
        # åˆ›å»ºæ•°æ®
        dataset = semantic_dataset(dataroot, 'v1.0-trainval')
        sample = dataset[0]
        
        imgs = sample[0].unsqueeze(0)  # æ·»åŠ batchç»´åº¦
        lidar_data = sample[1].unsqueeze(0)
        binimgs = sample[2].unsqueeze(0)
        
        if torch.cuda.is_available():
            model = model.cuda()
            imgs = imgs.cuda()
            lidar_data = lidar_data.cuda()
        
        # æ³¨å†Œhookæ¥æ•è·ä¸­é—´ç‰¹å¾
        features = {}
        def hook_fn(name):
            def hook(module, input, output):
                if isinstance(output, torch.Tensor):
                    features[name] = output.detach().cpu()
            return hook
        
        # ä¸ºå…³é”®å±‚æ³¨å†Œhook
        hooks = []
        for name, module in model.named_modules():
            if any(layer_type in name for layer_type in ['conv', 'bn', 'relu', 'pool']):
                hook = module.register_forward_hook(hook_fn(name))
                hooks.append(hook)
        
        # å‰å‘ä¼ æ’­
        model.eval()
        with torch.no_grad():
            output = model(imgs, lidar_data)
        
        # ç§»é™¤hooks
        for hook in hooks:
            hook.remove()
        
        print(f"âœ“ æ•è·åˆ° {len(features)} ä¸ªç‰¹å¾å›¾")
        
        # å¯è§†åŒ–ç‰¹å¾å›¾
        fig, axes = plt.subplots(2, 3, figsize=(15, 10))
        axes = axes.flatten()
        
        feature_names = list(features.keys())[:6]  # åªæ˜¾ç¤ºå‰6ä¸ª
        
        for i, name in enumerate(feature_names):
            feature = features[name]
            if feature.dim() == 4:  # [B, C, H, W]
                # æ˜¾ç¤ºç¬¬ä¸€ä¸ªé€šé“
                feature_map = feature[0, 0].numpy()
                axes[i].imshow(feature_map, cmap='viridis')
                axes[i].set_title(f'{name}\n{feature.shape}')
                axes[i].axis('off')
        
        plt.tight_layout()
        plt.savefig(os.path.join(save_dir, 'feature_maps.png'), dpi=150, bbox_inches='tight')
        plt.close()
        
        # å¯è§†åŒ–è¾“å…¥å’Œè¾“å‡º
        fig, axes = plt.subplots(2, 2, figsize=(12, 8))
        
        # è¾“å…¥å›¾åƒ (ç¬¬ä¸€ä¸ªç›¸æœº)
        img = imgs[0, 0].cpu().permute(1, 2, 0).numpy()
        img = (img - img.min()) / (img.max() - img.min())  # å½’ä¸€åŒ–åˆ°[0,1]
        axes[0, 0].imshow(img)
        axes[0, 0].set_title('è¾“å…¥å›¾åƒ (ç›¸æœº0)')
        axes[0, 0].axis('off')
        
        # æ¿€å…‰é›·è¾¾BEV
        lidar_bev = lidar_data[0, 0].cpu().numpy()
        axes[0, 1].imshow(lidar_bev, cmap='viridis')
        axes[0, 1].set_title('æ¿€å…‰é›·è¾¾BEV')
        axes[0, 1].axis('off')
        
        # é¢„æµ‹è¾“å‡º
        pred = torch.sigmoid(output[0, 0]).cpu().numpy()
        axes[1, 0].imshow(pred, cmap='viridis')
        axes[1, 0].set_title('é¢„æµ‹è¾“å‡º')
        axes[1, 0].axis('off')
        
        # çœŸå€¼æ ‡ç­¾
        gt = binimgs[0, 0].cpu().numpy()
        axes[1, 1].imshow(gt, cmap='viridis')
        axes[1, 1].set_title('çœŸå€¼æ ‡ç­¾')
        axes[1, 1].axis('off')
        
        plt.tight_layout()
        plt.savefig(os.path.join(save_dir, 'input_output.png'), dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"âœ“ ç‰¹å¾å¯è§†åŒ–ä¿å­˜åˆ°: {save_dir}/")
        print(f"  - feature_maps.png: ä¸­é—´ç‰¹å¾å›¾")
        print(f"  - input_output.png: è¾“å…¥è¾“å‡ºå¯¹æ¯”")
        
        return True
        
    except Exception as e:
        print(f"âŒ ç‰¹å¾å¯è§†åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    parser = argparse.ArgumentParser(description='SuperFusion è°ƒè¯•å·¥å…·é›†')
    parser.add_argument('--analyze-model', action='store_true', help='åˆ†ææ¨¡å‹ç»“æ„')
    parser.add_argument('--check-gradients', action='store_true', help='æ£€æŸ¥æ¢¯åº¦æµ')
    parser.add_argument('--profile-memory', action='store_true', help='å†…å­˜åˆ†æ')
    parser.add_argument('--test-dataloader', action='store_true', help='æµ‹è¯•æ•°æ®åŠ è½½å™¨')
    parser.add_argument('--visualize-features', action='store_true', help='å¯è§†åŒ–ç‰¹å¾')
    parser.add_argument('--model-path', type=str, help='æ¨¡å‹æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--dataroot', type=str, default='/path/to/nuScenes/', help='æ•°æ®é›†è·¯å¾„')
    parser.add_argument('--batch-size', type=int, default=4, help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--num-workers', type=int, default=4, help='æ•°æ®åŠ è½½è¿›ç¨‹æ•°')
    parser.add_argument('--save-dir', type=str, default='debug_vis', help='å¯è§†åŒ–ä¿å­˜ç›®å½•')
    parser.add_argument('--all', action='store_true', help='è¿è¡Œæ‰€æœ‰è°ƒè¯•å·¥å…·')
    
    args = parser.parse_args()
    
    if not any([args.analyze_model, args.check_gradients, args.profile_memory, 
                args.test_dataloader, args.visualize_features, args.all]):
        parser.print_help()
        return
    
    print("ğŸ”§ SuperFusion è°ƒè¯•å·¥å…·é›†")
    print("=" * 50)
    
    # æ¨¡å‹åˆ†æ
    if args.analyze_model or args.all:
        analyze_model()
    
    # æ¢¯åº¦æ£€æŸ¥
    if args.check_gradients or args.all:
        check_gradients(args.model_path, args.dataroot)
    
    # å†…å­˜åˆ†æ
    if args.profile_memory or args.all:
        profile_memory(batch_size=args.batch_size)
    
    # æ•°æ®åŠ è½½å™¨æµ‹è¯•
    if args.test_dataloader or args.all:
        test_dataloader(args.dataroot, args.batch_size, args.num_workers)
    
    # ç‰¹å¾å¯è§†åŒ–
    if args.visualize_features or args.all:
        visualize_features(args.model_path, args.dataroot, args.save_dir)
    
    print("\n" + "=" * 50)
    print("ğŸ‰ è°ƒè¯•å·¥å…·è¿è¡Œå®Œæˆ!")

if __name__ == '__main__':
    main()