#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SuperFusion æ¨ç†ç¤ºä¾‹
å±•ç¤ºå¦‚ä½•ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œè½¦é“çº¿æ£€æµ‹

ä½¿ç”¨æ–¹æ³•:
python inference_example.py --model_path runs/model.pt --data_sample sample_001
"""

import os
import sys
import argparse
import numpy as np
from pathlib import Path
import json

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('.')
from inference import SuperFusionInference

def create_sample_data(output_dir='sample_data'):
    """
    åˆ›å»ºç¤ºä¾‹è¾“å…¥æ•°æ®
    
    Args:
        output_dir: è¾“å‡ºç›®å½•
    """
    print(f"\nğŸ“ åˆ›å»ºç¤ºä¾‹æ•°æ®åˆ°: {output_dir}")
    os.makedirs(output_dir, exist_ok=True)
    
    # åˆ›å»ºç¤ºä¾‹å›¾åƒæ•°æ® (æ¨¡æ‹Ÿ6ä¸ªç›¸æœº)
    img_size = (256, 704, 3)  # H, W, C
    camera_names = ['front', 'front_right', 'front_left', 'back', 'back_left', 'back_right']
    
    image_paths = []
    for i, cam_name in enumerate(camera_names):
        # åˆ›å»ºæ¨¡æ‹Ÿå›¾åƒæ•°æ®
        img_data = np.random.randint(0, 255, img_size, dtype=np.uint8)
        
        # æ·»åŠ ä¸€äº›æ¨¡æ‹Ÿçš„é“è·¯å’Œè½¦é“çº¿ç‰¹å¾
        # é“è·¯åŒºåŸŸ (ä¸‹åŠéƒ¨åˆ†)
        img_data[img_size[0]//2:, :] = [100, 100, 100]  # ç°è‰²é“è·¯
        
        # è½¦é“çº¿ (ç™½è‰²çº¿æ¡)
        for lane_x in [img_size[1]//4, img_size[1]//2, 3*img_size[1]//4]:
            img_data[img_size[0]//2:, lane_x-2:lane_x+2] = [255, 255, 255]
        
        # ä¿å­˜å›¾åƒ
        from PIL import Image
        img_path = os.path.join(output_dir, f'{cam_name}.jpg')
        Image.fromarray(img_data).save(img_path)
        image_paths.append(img_path)
        
        print(f"  âœ“ åˆ›å»º {cam_name} å›¾åƒ: {img_path}")
    
    # åˆ›å»ºç¤ºä¾‹æ¿€å…‰é›·è¾¾BEVæ•°æ®
    bev_size = (200, 200, 5)  # H, W, C (5ä¸ªç‰¹å¾é€šé“)
    lidar_data = np.random.randn(*bev_size).astype(np.float32)
    
    # æ·»åŠ ä¸€äº›æ¨¡æ‹Ÿçš„è½¦é“çº¿ç‰¹å¾
    for lane_y in [50, 100, 150]:
        lidar_data[lane_y-2:lane_y+2, :, 0] = 2.0  # å¼ºåŒ–ç¬¬ä¸€ä¸ªé€šé“çš„è½¦é“çº¿ä¿¡å·
    
    lidar_path = os.path.join(output_dir, 'lidar_bev.npy')
    np.save(lidar_path, lidar_data)
    print(f"  âœ“ åˆ›å»ºæ¿€å…‰é›·è¾¾BEVæ•°æ®: {lidar_path}")
    
    return image_paths, lidar_path

def load_nuscenes_sample(dataroot, sample_token):
    """
    ä»nuScenesæ•°æ®é›†åŠ è½½çœŸå®æ ·æœ¬
    
    Args:
        dataroot: nuScenesæ•°æ®é›†è·¯å¾„
        sample_token: æ ·æœ¬token
        
    Returns:
        tuple: (image_paths, lidar_path)
    """
    try:
        from nuscenes.nuscenes import NuScenes
        from data.dataset_front import semantic_dataset
        
        print(f"\nğŸ“ ä»nuScenesåŠ è½½æ ·æœ¬: {sample_token}")
        
        # åˆå§‹åŒ–nuScenes
        nusc = NuScenes(version='v1.0-trainval', dataroot=dataroot, verbose=False)
        
        # è·å–æ ·æœ¬
        sample = nusc.get('sample', sample_token)
        
        # è·å–ç›¸æœºæ•°æ®
        camera_names = ['CAM_FRONT', 'CAM_FRONT_RIGHT', 'CAM_FRONT_LEFT', 
                       'CAM_BACK', 'CAM_BACK_LEFT', 'CAM_BACK_RIGHT']
        
        image_paths = []
        for cam_name in camera_names:
            cam_token = sample['data'][cam_name]
            cam_data = nusc.get('sample_data', cam_token)
            img_path = os.path.join(dataroot, cam_data['filename'])
            image_paths.append(img_path)
            print(f"  âœ“ {cam_name}: {img_path}")
        
        # è·å–æ¿€å…‰é›·è¾¾æ•°æ® (è¿™é‡Œéœ€è¦é¢„å¤„ç†ä¸ºBEVæ ¼å¼)
        lidar_token = sample['data']['LIDAR_TOP']
        lidar_data = nusc.get('sample_data', lidar_token)
        lidar_path = os.path.join(dataroot, lidar_data['filename'])
        
        print(f"  âœ“ LIDAR: {lidar_path}")
        print(f"  âš ï¸ æ³¨æ„: æ¿€å…‰é›·è¾¾æ•°æ®éœ€è¦é¢„å¤„ç†ä¸ºBEVæ ¼å¼")
        
        return image_paths, lidar_path
        
    except Exception as e:
        print(f"âŒ åŠ è½½nuScenesæ ·æœ¬å¤±è´¥: {e}")
        return None, None

def run_inference_example(model_path, image_paths, lidar_path, output_dir='inference_results'):
    """
    è¿è¡Œæ¨ç†ç¤ºä¾‹
    
    Args:
        model_path: æ¨¡å‹è·¯å¾„
        image_paths: å›¾åƒè·¯å¾„åˆ—è¡¨
        lidar_path: æ¿€å…‰é›·è¾¾æ•°æ®è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
    """
    print(f"\nğŸš€ å¼€å§‹æ¨ç†ç¤ºä¾‹")
    print(f"æ¨¡å‹è·¯å¾„: {model_path}")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")
    
    try:
        # åˆå§‹åŒ–æ¨ç†å™¨
        inferencer = SuperFusionInference(model_path)
        
        # æ‰§è¡Œæ¨ç†
        print("\nğŸ” æ‰§è¡Œæ¨ç†...")
        results = inferencer.predict(image_paths, lidar_path)
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        
        # ä¿å­˜åŸå§‹ç»“æœ
        result_file = os.path.join(output_dir, 'raw_results.npz')
        save_data = {}
        for key, value in results.items():
            if isinstance(value, dict):
                for sub_key, sub_value in value.items():
                    save_data[f"{key}_{sub_key}"] = sub_value
            else:
                save_data[key] = value
        
        np.savez(result_file, **save_data)
        print(f"âœ“ åŸå§‹ç»“æœä¿å­˜åˆ°: {result_file}")
        
        # ç”Ÿæˆå¯è§†åŒ–
        print("\nğŸ¨ ç”Ÿæˆå¯è§†åŒ–...")
        vis_path = os.path.join(output_dir, 'lane_detection.png')
        inferencer.visualize_results(results, vis_path)
        
        # çŸ¢é‡åŒ–è½¦é“çº¿
        print("\nğŸ“ çŸ¢é‡åŒ–è½¦é“çº¿...")
        lanes = inferencer.vectorize_lanes(results)
        
        # ä¿å­˜çŸ¢é‡ç»“æœ
        vector_file = os.path.join(output_dir, 'detected_lanes.json')
        lane_data = {
            'lanes': lanes,
            'num_lanes': len(lanes),
            'bev_params': inferencer.bev_params,
            'metadata': {
                'model_path': model_path,
                'input_images': image_paths,
                'input_lidar': lidar_path
            }
        }
        
        with open(vector_file, 'w') as f:
            json.dump(lane_data, f, indent=2)
        
        print(f"âœ“ æ£€æµ‹åˆ° {len(lanes)} æ¡è½¦é“çº¿")
        print(f"âœ“ çŸ¢é‡ç»“æœä¿å­˜åˆ°: {vector_file}")
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        seg_shape = results['segmentation']['shape']
        seg_binary = results['segmentation']['binary']
        
        print(f"\nğŸ“Š æ£€æµ‹ç»Ÿè®¡:")
        print(f"åˆ†å‰²å›¾å°ºå¯¸: {seg_shape}")
        print(f"è½¦é“çº¿åƒç´ æ•°: {np.sum(seg_binary)}")
        print(f"è½¦é“çº¿è¦†ç›–ç‡: {np.sum(seg_binary) / np.prod(seg_shape[1:]) * 100:.2f}%")
        
        # å¦‚æœæœ‰å¤šä¸ªè¾“å‡ºï¼Œæ˜¾ç¤ºé¢å¤–ä¿¡æ¯
        if 'embedding' in results:
            print(f"åµŒå…¥ç‰¹å¾ç»´åº¦: {results['embedding'].shape}")
        if 'direction' in results:
            print(f"æ–¹å‘é¢„æµ‹ç»´åº¦: {results['direction'].shape}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¨ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    parser = argparse.ArgumentParser(description='SuperFusionæ¨ç†ç¤ºä¾‹')
    parser.add_argument('--model_path', type=str, required=True, help='é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„')
    parser.add_argument('--data_sample', type=str, help='æ ·æœ¬æ•°æ®ç›®å½•æˆ–nuScenesæ ·æœ¬token')
    parser.add_argument('--dataroot', type=str, help='nuScenesæ•°æ®é›†è·¯å¾„ (å¦‚æœä½¿ç”¨çœŸå®æ•°æ®)')
    parser.add_argument('--output_dir', type=str, default='inference_results', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--create_sample', action='store_true', help='åˆ›å»ºç¤ºä¾‹æ•°æ®')
    
    args = parser.parse_args()
    
    print("ğŸš€ SuperFusionæ¨ç†ç¤ºä¾‹")
    print("=" * 50)
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    if not os.path.exists(args.model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {args.model_path}")
        print("\nğŸ’¡ è·å–é¢„è®­ç»ƒæ¨¡å‹çš„æ–¹æ³•:")
        print("1. ä»å®˜æ–¹ä¸‹è½½: https://drive.google.com/file/d/1UTgughJ71Rn0zPUDTXFo__HJS-57lwNG/view")
        print("2. è‡ªå·±è®­ç»ƒ: python train.py --dataroot /path/to/nuScenes/ --instance_seg --direction_pred --depth_sup --pretrained")
        return 1
    
    # å‡†å¤‡è¾“å…¥æ•°æ®
    image_paths = None
    lidar_path = None
    
    if args.create_sample or not args.data_sample:
        # åˆ›å»ºç¤ºä¾‹æ•°æ®
        sample_dir = args.data_sample or 'sample_data'
        image_paths, lidar_path = create_sample_data(sample_dir)
        
    elif args.dataroot and len(args.data_sample) == 32:  # nuScenesæ ·æœ¬tokené•¿åº¦
        # ä»nuScenesåŠ è½½çœŸå®æ•°æ®
        image_paths, lidar_path = load_nuscenes_sample(args.dataroot, args.data_sample)
        if image_paths is None:
            print("âŒ æ— æ³•åŠ è½½nuScenesæ•°æ®ï¼Œå°†åˆ›å»ºç¤ºä¾‹æ•°æ®")
            image_paths, lidar_path = create_sample_data('sample_data')
    
    elif os.path.isdir(args.data_sample):
        # ä»æŒ‡å®šç›®å½•åŠ è½½æ•°æ®
        print(f"\nğŸ“ ä»ç›®å½•åŠ è½½æ•°æ®: {args.data_sample}")
        
        # æŸ¥æ‰¾å›¾åƒæ–‡ä»¶
        camera_names = ['front', 'front_right', 'front_left', 'back', 'back_left', 'back_right']
        image_paths = []
        
        for cam_name in camera_names:
            for ext in ['.jpg', '.jpeg', '.png']:
                img_path = os.path.join(args.data_sample, f'{cam_name}{ext}')
                if os.path.exists(img_path):
                    image_paths.append(img_path)
                    break
            else:
                print(f"âŒ æ‰¾ä¸åˆ° {cam_name} å›¾åƒ")
                return 1
        
        # æŸ¥æ‰¾æ¿€å…‰é›·è¾¾æ–‡ä»¶
        lidar_path = os.path.join(args.data_sample, 'lidar_bev.npy')
        if not os.path.exists(lidar_path):
            print(f"âŒ æ‰¾ä¸åˆ°æ¿€å…‰é›·è¾¾æ–‡ä»¶: {lidar_path}")
            return 1
    
    else:
        print(f"âŒ æ— æ•ˆçš„æ•°æ®æ ·æœ¬: {args.data_sample}")
        return 1
    
    # éªŒè¯è¾“å…¥æ•°æ®
    if len(image_paths) != 6:
        print(f"âŒ éœ€è¦6ä¸ªç›¸æœºå›¾åƒï¼Œä½†æ‰¾åˆ°{len(image_paths)}ä¸ª")
        return 1
    
    for img_path in image_paths:
        if not os.path.exists(img_path):
            print(f"âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {img_path}")
            return 1
    
    if not os.path.exists(lidar_path):
        print(f"âŒ æ¿€å…‰é›·è¾¾æ–‡ä»¶ä¸å­˜åœ¨: {lidar_path}")
        return 1
    
    # è¿è¡Œæ¨ç†
    success = run_inference_example(args.model_path, image_paths, lidar_path, args.output_dir)
    
    if success:
        print("\n" + "=" * 50)
        print("ğŸ‰ æ¨ç†ç¤ºä¾‹å®Œæˆ!")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {args.output_dir}/")
        print("\nğŸ“‹ è¾“å‡ºæ–‡ä»¶:")
        print(f"  - raw_results.npz: åŸå§‹é¢„æµ‹ç»“æœ")
        print(f"  - lane_detection.png: å¯è§†åŒ–å›¾åƒ")
        print(f"  - detected_lanes.json: çŸ¢é‡åŒ–è½¦é“çº¿")
        
        print("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
        print("1. æŸ¥çœ‹å¯è§†åŒ–å›¾åƒäº†è§£æ£€æµ‹æ•ˆæœ")
        print("2. æ£€æŸ¥JSONæ–‡ä»¶ä¸­çš„è½¦é“çº¿åæ ‡")
        print("3. æ ¹æ®éœ€è¦è°ƒæ•´åå¤„ç†å‚æ•°")
        
        return 0
    else:
        return 1

if __name__ == '__main__':
    exit(main())