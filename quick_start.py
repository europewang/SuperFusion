#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SuperFusion å¿«é€Ÿå¯åŠ¨è„šæœ¬
ç”¨äºç¯å¢ƒéªŒè¯ã€æ•°æ®æ£€æŸ¥å’ŒåŸºç¡€æµ‹è¯•

ä½¿ç”¨æ–¹æ³•:
python quick_start.py --check-env          # æ£€æŸ¥ç¯å¢ƒ
python quick_start.py --check-data         # æ£€æŸ¥æ•°æ®
python quick_start.py --test-model         # æµ‹è¯•æ¨¡å‹
python quick_start.py --mini-train         # è¿·ä½ è®­ç»ƒæµ‹è¯•
"""

import os
import sys
import argparse
import torch
import numpy as np
from pathlib import Path

def check_environment():
    """æ£€æŸ¥è¿è¡Œç¯å¢ƒ"""
    print("ğŸ” æ£€æŸ¥è¿è¡Œç¯å¢ƒ...")
    
    # Pythonç‰ˆæœ¬
    python_version = sys.version_info
    print(f"âœ“ Pythonç‰ˆæœ¬: {python_version.major}.{python_version.minor}.{python_version.micro}")
    
    # PyTorchç‰ˆæœ¬
    print(f"âœ“ PyTorchç‰ˆæœ¬: {torch.__version__}")
    
    # CUDAå¯ç”¨æ€§
    if torch.cuda.is_available():
        print(f"âœ“ CUDAå¯ç”¨: {torch.cuda.get_device_name(0)}")
        print(f"âœ“ GPUæ•°é‡: {torch.cuda.device_count()}")
        print(f"âœ“ GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    else:
        print("âŒ CUDAä¸å¯ç”¨")
        return False
    
    # æ£€æŸ¥å…³é”®ä¾èµ–åŒ…
    required_packages = [
        'torchvision', 'kornia', 'numpy', 'tensorboardX', 
        'PIL', 'pyquaternion', 'nuscenes', 'inplace_abn', 
        'torch_scatter', 'shapely'
    ]
    
    missing_packages = []
    for package in required_packages:
        try:
            if package == 'PIL':
                import PIL
            elif package == 'nuscenes':
                from nuscenes.nuscenes import NuScenes
            else:
                __import__(package)
            print(f"âœ“ {package}: å·²å®‰è£…")
        except ImportError:
            print(f"âŒ {package}: æœªå®‰è£…")
            missing_packages.append(package)
    
    if missing_packages:
        print(f"\nâŒ ç¼ºå°‘ä¾èµ–åŒ…: {', '.join(missing_packages)}")
        print("è¯·è¿è¡Œ: pip install -r requirement.txt")
        return False
    
    print("\nâœ… ç¯å¢ƒæ£€æŸ¥é€šè¿‡!")
    return True

def check_data(dataroot):
    """æ£€æŸ¥æ•°æ®é›†"""
    print(f"\nğŸ” æ£€æŸ¥æ•°æ®é›†: {dataroot}")
    
    if not os.path.exists(dataroot):
        print(f"âŒ æ•°æ®è·¯å¾„ä¸å­˜åœ¨: {dataroot}")
        return False
    
    # æ£€æŸ¥å¿…è¦çš„ç›®å½•ç»“æ„
    required_dirs = ['maps', 'samples', 'sweeps', 'v1.0-trainval']
    missing_dirs = []
    
    for dir_name in required_dirs:
        dir_path = os.path.join(dataroot, dir_name)
        if os.path.exists(dir_path):
            print(f"âœ“ {dir_name}: å­˜åœ¨")
        else:
            print(f"âŒ {dir_name}: ä¸å­˜åœ¨")
            missing_dirs.append(dir_name)
    
    if missing_dirs:
        print(f"\nâŒ ç¼ºå°‘ç›®å½•: {', '.join(missing_dirs)}")
        return False
    
    # å°è¯•åŠ è½½nuScenesæ•°æ®é›†
    try:
        from nuscenes.nuscenes import NuScenes
        nusc = NuScenes(version='v1.0-trainval', dataroot=dataroot, verbose=False)
        print(f"âœ“ nuScenesæ•°æ®é›†åŠ è½½æˆåŠŸ")
        print(f"âœ“ åœºæ™¯æ•°é‡: {len(nusc.scene)}")
        print(f"âœ“ æ ·æœ¬æ•°é‡: {len(nusc.sample)}")
    except Exception as e:
        print(f"âŒ nuScenesæ•°æ®é›†åŠ è½½å¤±è´¥: {e}")
        return False
    
    print("\nâœ… æ•°æ®æ£€æŸ¥é€šè¿‡!")
    return True

def check_pretrained_models():
    """æ£€æŸ¥é¢„è®­ç»ƒæ¨¡å‹"""
    print("\nğŸ” æ£€æŸ¥é¢„è®­ç»ƒæ¨¡å‹...")
    
    # æ£€æŸ¥checkpointsç›®å½•
    checkpoints_dir = Path('checkpoints')
    if not checkpoints_dir.exists():
        print("âŒ checkpointsç›®å½•ä¸å­˜åœ¨")
        print("è¯·åˆ›å»ºç›®å½•: mkdir checkpoints")
        return False
    
    # æ£€æŸ¥DeepLabV3é¢„è®­ç»ƒæ¨¡å‹
    deeplabv3_path = checkpoints_dir / 'deeplabv3_resnet101_coco-586e9e4e.pth'
    if deeplabv3_path.exists():
        print("âœ“ DeepLabV3é¢„è®­ç»ƒæ¨¡å‹å­˜åœ¨")
        try:
            torch.load(deeplabv3_path, map_location='cpu')
            print("âœ“ DeepLabV3æ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"âŒ DeepLabV3æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False
    else:
        print("âŒ DeepLabV3é¢„è®­ç»ƒæ¨¡å‹ä¸å­˜åœ¨")
        print("è¯·ä¸‹è½½: wget https://download.pytorch.org/models/deeplabv3_resnet101_coco-586e9e4e.pth -O checkpoints/deeplabv3_resnet101_coco-586e9e4e.pth")
        return False
    
    print("\nâœ… é¢„è®­ç»ƒæ¨¡å‹æ£€æŸ¥é€šè¿‡!")
    return True

def test_model_loading():
    """æµ‹è¯•æ¨¡å‹åŠ è½½"""
    print("\nğŸ” æµ‹è¯•æ¨¡å‹åŠ è½½...")
    
    try:
        # å¯¼å…¥æ¨¡å‹
        sys.path.append('.')
        from model_front import get_model
        
        # åˆ›å»ºæ¨¡å‹é…ç½®
        args = type('Args', (), {
            'instance_seg': True,
            'direction_pred': True,
            'depth_sup': True,
            'add_depth_channel': True,
            'pretrained': True,
            'camC': 64,
            'lidarC': 64,
            'downsample': 16,
            'use_lidar': True,
            'use_cam': True,
            'use_fusion': True,
            'add_fuser': True
        })()
        
        # åˆ›å»ºæ¨¡å‹
        model = get_model('SuperFusion', args)
        print("âœ“ æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        # è®¡ç®—å‚æ•°é‡
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        print(f"âœ“ æ€»å‚æ•°é‡: {total_params/1e6:.2f}M")
        print(f"âœ“ å¯è®­ç»ƒå‚æ•°é‡: {trainable_params/1e6:.2f}M")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        model.eval()
        with torch.no_grad():
            # åˆ›å»ºè™šæ‹Ÿè¾“å…¥
            batch_size = 1
            imgs = torch.randn(batch_size, 6, 3, 256, 704)  # 6ä¸ªç›¸æœº
            lidar_data = torch.randn(batch_size, 5, 256, 704)  # æ¿€å…‰é›·è¾¾BEV
            
            if torch.cuda.is_available():
                model = model.cuda()
                imgs = imgs.cuda()
                lidar_data = lidar_data.cuda()
            
            # å‰å‘ä¼ æ’­
            output = model(imgs, lidar_data)
            print(f"âœ“ å‰å‘ä¼ æ’­æˆåŠŸ, è¾“å‡ºå½¢çŠ¶: {output.shape}")
        
        print("\nâœ… æ¨¡å‹æµ‹è¯•é€šè¿‡!")
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def mini_train_test(dataroot):
    """è¿·ä½ è®­ç»ƒæµ‹è¯•"""
    print("\nğŸ” è¿·ä½ è®­ç»ƒæµ‹è¯•...")
    
    try:
        # å¯¼å…¥è®­ç»ƒç›¸å…³æ¨¡å—
        sys.path.append('.')
        from data.dataset_front import semantic_dataset
        from model_front import get_model
        from loss import SimpleLoss
        
        # åˆ›å»ºæ•°æ®é›†
        dataset = semantic_dataset(dataroot, 'v1.0-trainval')
        print(f"âœ“ æ•°æ®é›†åˆ›å»ºæˆåŠŸ, æ ·æœ¬æ•°é‡: {len(dataset)}")
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        dataloader = torch.utils.data.DataLoader(
            dataset, batch_size=1, shuffle=False, num_workers=0
        )
        
        # è·å–ä¸€ä¸ªæ ·æœ¬
        sample = next(iter(dataloader))
        print(f"âœ“ æ•°æ®åŠ è½½æˆåŠŸ")
        print(f"  - å›¾åƒå½¢çŠ¶: {sample[0].shape}")
        print(f"  - æ¿€å…‰é›·è¾¾å½¢çŠ¶: {sample[1].shape}")
        print(f"  - æ ‡ç­¾å½¢çŠ¶: {sample[2].shape}")
        
        # åˆ›å»ºæ¨¡å‹
        args = type('Args', (), {
            'instance_seg': False,  # ç®€åŒ–æµ‹è¯•
            'direction_pred': False,
            'depth_sup': False,
            'add_depth_channel': False,
            'pretrained': True,
            'camC': 64,
            'lidarC': 64,
            'downsample': 16,
            'use_lidar': True,
            'use_cam': True,
            'use_fusion': True,
            'add_fuser': True
        })()
        
        model = get_model('SuperFusion', args)
        print("âœ“ æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        # åˆ›å»ºæŸå¤±å‡½æ•°
        loss_fn = SimpleLoss(pos_weight=2.13)
        
        # åˆ›å»ºä¼˜åŒ–å™¨
        optimizer = torch.optim.SGD(model.parameters(), lr=0.01)
        
        if torch.cuda.is_available():
            model = model.cuda()
            loss_fn = loss_fn.cuda()
            sample = [s.cuda() if torch.is_tensor(s) else s for s in sample]
        
        # è®­ç»ƒä¸€æ­¥
        model.train()
        optimizer.zero_grad()
        
        imgs, lidar_data, binimgs = sample[0], sample[1], sample[2]
        output = model(imgs, lidar_data)
        loss = loss_fn(output, binimgs)
        
        loss.backward()
        optimizer.step()
        
        print(f"âœ“ è®­ç»ƒä¸€æ­¥æˆåŠŸ, æŸå¤±å€¼: {loss.item():.4f}")
        print("\nâœ… è¿·ä½ è®­ç»ƒæµ‹è¯•é€šè¿‡!")
        return True
        
    except Exception as e:
        print(f"âŒ è¿·ä½ è®­ç»ƒæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    parser = argparse.ArgumentParser(description='SuperFusion å¿«é€Ÿå¯åŠ¨è„šæœ¬')
    parser.add_argument('--check-env', action='store_true', help='æ£€æŸ¥ç¯å¢ƒ')
    parser.add_argument('--check-data', action='store_true', help='æ£€æŸ¥æ•°æ®')
    parser.add_argument('--test-model', action='store_true', help='æµ‹è¯•æ¨¡å‹')
    parser.add_argument('--mini-train', action='store_true', help='è¿·ä½ è®­ç»ƒæµ‹è¯•')
    parser.add_argument('--dataroot', type=str, default='/path/to/nuScenes/', 
                       help='nuScenesæ•°æ®é›†è·¯å¾„')
    parser.add_argument('--all', action='store_true', help='è¿è¡Œæ‰€æœ‰æ£€æŸ¥')
    
    args = parser.parse_args()
    
    if not any([args.check_env, args.check_data, args.test_model, args.mini_train, args.all]):
        parser.print_help()
        return
    
    print("ğŸš€ SuperFusion å¿«é€Ÿå¯åŠ¨æ£€æŸ¥")
    print("=" * 50)
    
    success = True
    
    # ç¯å¢ƒæ£€æŸ¥
    if args.check_env or args.all:
        if not check_environment():
            success = False
        if not check_pretrained_models():
            success = False
    
    # æ•°æ®æ£€æŸ¥
    if args.check_data or args.all:
        if not check_data(args.dataroot):
            success = False
    
    # æ¨¡å‹æµ‹è¯•
    if args.test_model or args.all:
        if not test_model_loading():
            success = False
    
    # è¿·ä½ è®­ç»ƒæµ‹è¯•
    if args.mini_train or args.all:
        if not mini_train_test(args.dataroot):
            success = False
    
    print("\n" + "=" * 50)
    if success:
        print("ğŸ‰ æ‰€æœ‰æ£€æŸ¥é€šè¿‡! å¯ä»¥å¼€å§‹ä½¿ç”¨SuperFusionäº†")
        print("\nğŸ“š ä¸‹ä¸€æ­¥:")
        print("1. è®­ç»ƒæ¨¡å‹: python train.py --dataroot /path/to/nuScenes/ --instance_seg --direction_pred --depth_sup --pretrained --add_depth_channel")
        print("2. è¯„ä¼°æ¨¡å‹: python evaluate_iou_split.py --dataroot /path/to/nuScenes/ --modelf runs/model.pt")
        print("3. å¯è§†åŒ–ç»“æœ: python vis_prediction.py --modelf runs/model.pt --dataroot /path/to/nuScenes/")
    else:
        print("âŒ éƒ¨åˆ†æ£€æŸ¥å¤±è´¥ï¼Œè¯·æ ¹æ®ä¸Šè¿°æç¤ºè§£å†³é—®é¢˜")
        sys.exit(1)

if __name__ == '__main__':
    main()